{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tjnet_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMu/p8OP5F+gZML6e0N2lLQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zAlg_duAo5U2","executionInfo":{"status":"ok","timestamp":1629184750063,"user_tz":-540,"elapsed":5841,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import torch"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqZt5wWhCy3E","executionInfo":{"status":"ok","timestamp":1629184751854,"user_tz":-540,"elapsed":365,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["#separable 합성곱 함수\n","def separable_conv(x,inchannel,outchannel):\n","  x = keras.layers.Conv2D(inchannel,(3,3),strides=1,padding=\"same\")(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Conv2D(outchannel,(1,1),strides=1,padding=\"same\")(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  return x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoNcLq3-4MTn","executionInfo":{"status":"ok","timestamp":1629184756630,"user_tz":-540,"elapsed":325,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["#model middle_flow 함수\n","def middle_flow(input_x):\n","  #encoder\n","  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(input_x)\n","  x = resiual_units(x)\n","  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n","  x = resiual_units(x)\n","  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n","  x = resiual_units(x)\n","  \n","  \n","\n","  #decoder\n","  x = resiual_units(x)\n","  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n","  x = resiual_units(x)\n","  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n","  x = resiual_units(x)\n","  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n","  \n","  x = separable_conv(x,x.shape[-1],512)\n","  x = separable_conv(x,x.shape[-1],512) \n","  \n","  #sigmoid \n","  x = keras.activations.sigmoid(x)\n","  x = keras.layers.Multiply()([input_x,x])\n","  x = keras.layers.Add()([input_x,x])\n","\n","  x = resiual_units(x)\n","\n","  return x"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3atKab8Fim-","executionInfo":{"status":"ok","timestamp":1629184758772,"user_tz":-540,"elapsed":247,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["#resiual_units 함수 \n","def resiual_units(input_x):\n","  x = keras.layers.ReLU()(input_x)\n","  x = separable_conv(x,x.shape[-1],128)\n","  x = keras.layers.BatchNormalization()(x)\n","\n","  x = keras.layers.ReLU()(x)\n","  x = separable_conv(x,x.shape[-1],256)\n","  x = keras.layers.BatchNormalization()(x)\n","\n","  x = keras.layers.ReLU()(x)\n","  x = separable_conv(x,x.shape[-1],512)\n","  x = keras.layers.BatchNormalization()(x)\n","  \n","  input_x = keras.layers.Add()([x,input_x])\n","\n","  return input_x"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tS2wIBapuSV8","executionInfo":{"status":"ok","timestamp":1629184768190,"user_tz":-540,"elapsed":7795,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["#골연령 측정 모델\n","#entry flow model\n","input = keras.Input(shape=(256,256,1))\n","x = keras.layers.Conv2D(32,(3,3),strides=2)(input)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.ReLU()(x)\n","\n","x = keras.layers.Conv2D(64,(3,3),strides=1)(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.ReLU()(x)\n","#첫번째\n","x1 = keras.layers.Conv2D(128,(1,1),strides=2)(x) \n","x1 = keras.layers.BatchNormalization()(x1)\n","\n","x = separable_conv(x,x.shape[-1],128)\n","x = keras.layers.ReLU()(x)\n","\n","x = separable_conv(x,x.shape[-1],128)\n","x = keras.layers.ReLU()(x)\n","x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n","\n","x = keras.layers.Add()([x,x1])\n","#2번째\n","x1 = keras.layers.Conv2D(512,(1,1),strides=2)(x)\n","x1 = keras.layers.BatchNormalization()(x1)\n","\n","x = separable_conv(x,x.shape[-1],512)\n","x = keras.layers.ReLU()(x)\n","\n","x = separable_conv(x,x.shape[-1],512)\n","x = keras.layers.ReLU()(x)\n","x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n","\n","x = keras.layers.Add()([x,x1])\n","\n","\n","#middle flow model\n","x = middle_flow(x)\n","\n","\n","#exit flow model\n","x1 = keras.layers.Conv2D(1024,(1,1),strides=2)(x)\n","\n","x = keras.layers.ReLU()(x)\n","x = separable_conv(x,x.shape[-1],728)\n","x = keras.layers.ReLU()(x)\n","x = separable_conv(x,x.shape[-1],1024)\n","x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n","\n","x = keras.layers.Add()([x,x1])\n","\n","\n","x = separable_conv(x,x.shape[-1],1536)\n","x = keras.layers.ReLU()(x)\n","x = separable_conv(x,x.shape[-1],2048)\n","x = keras.layers.ReLU()(x)\n","\n","x = keras.layers.GlobalAvgPool2D()(x)\n","\n","x = keras.layers.Dense(1000,activation='relu')(x)\n","x = keras.layers.Dense(256,activation='relu')(x)\n","x = keras.layers.Dense(1)(x)\n","\n","model = keras.models.Model(input,x)\n","model.compile(optimizer='adam',loss='mae',metrics=['mae','mse'])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wj0D81cdlrpi","executionInfo":{"status":"ok","timestamp":1628744732769,"user_tz":-540,"elapsed":1395,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"9d6bb2df-6f2b-40cf-f1c8-d3e59a5dfefb"},"source":["model.save('./tjnet_model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EfMsYaFdubUk"},"source":["from tensorflow.python.keras.utils.vis_utils import model_to_dot\n","from IPython.display import SVG\n","import pydot\n","import graphviz\n","\n","SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='TB',expand_nested=False, dpi=60, subgraph=False).create(prog='dot',format='svg'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0K3Cm4z6ztM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629184776523,"user_tz":-540,"elapsed":245,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"97964057-6c86-437c-c154-d2b04edb398a"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"klFJwhEMz1JZ","executionInfo":{"status":"ok","timestamp":1629184874438,"user_tz":-540,"elapsed":256,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["from sklearn.model_selection import train_test_split\n","from keras.callbacks import ModelCheckpoint\n","\n","bones = np.load('/content/cboneage.npy',allow_pickle=True)\n","X_data = bones[:,2]\n","y = bones[:,1]\n","\n","\n","filename = 'checkpoint-50-epochs-16-batchs.h5'\n","checkpoint = ModelCheckpoint(filename,mointor='val_loss',verbose=1,save_best_only=True,mode='auto')\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"zM-kOsJ-sXsp","executionInfo":{"status":"ok","timestamp":1629184896410,"user_tz":-540,"elapsed":14437,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["tmp = np.zeros((256,256))\n","for _,x in enumerate(X_data):\n","  if _ == 0:\n","    tmp = x\n","    tmp = tmp.reshape(1,256,256)\n","  else:\n","    tmp = np.concatenate([tmp,x.reshape(1,256,256)])\n","    \n","X_data = tmp"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kfCkJrVzF6E","executionInfo":{"status":"ok","timestamp":1629184945389,"user_tz":-540,"elapsed":233,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}}},"source":["np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.1f}\".format(x)})\n","y = y.astype(np.float)\n","\n","train_x,test_x,train_y,test_y = train_test_split(X_data.reshape(1205,256,256,-1),y,random_state=42,test_size=0.2)\n","train_x,val_x,train_y,val_y = train_test_split(train_x,train_y,random_state=42,test_size=0.2)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rPfuD_0t70D","executionInfo":{"status":"ok","timestamp":1629193722429,"user_tz":-540,"elapsed":6803993,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"55e8e236-903b-436e-cf6a-09fba92d56d7"},"source":["with tf.device('/device:GPU:0'):\n","  model.fit(train_x,train_y,batch_size=16,epochs=150,callbacks=checkpoint,validation_data=(val_x,val_y))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","49/49 [==============================] - 45s 915ms/step - loss: 1.1653 - mae: 1.1653 - mse: 2.2619 - val_loss: 2.2775 - val_mae: 2.2775 - val_mse: 7.4966\n","\n","Epoch 00001: val_loss did not improve from 1.35714\n","Epoch 2/150\n","49/49 [==============================] - 45s 909ms/step - loss: 0.8212 - mae: 0.8212 - mse: 1.2328 - val_loss: 2.7072 - val_mae: 2.7072 - val_mse: 9.7674\n","\n","Epoch 00002: val_loss did not improve from 1.35714\n","Epoch 3/150\n","49/49 [==============================] - 45s 914ms/step - loss: 1.0455 - mae: 1.0455 - mse: 1.8425 - val_loss: 2.9642 - val_mae: 2.9642 - val_mse: 13.7671\n","\n","Epoch 00003: val_loss did not improve from 1.35714\n","Epoch 4/150\n","49/49 [==============================] - 45s 914ms/step - loss: 1.0241 - mae: 1.0241 - mse: 1.8603 - val_loss: 3.9617 - val_mae: 3.9617 - val_mse: 20.4213\n","\n","Epoch 00004: val_loss did not improve from 1.35714\n","Epoch 5/150\n","49/49 [==============================] - 45s 915ms/step - loss: 1.0221 - mae: 1.0221 - mse: 1.7776 - val_loss: 4.3952 - val_mae: 4.3952 - val_mse: 22.7930\n","\n","Epoch 00005: val_loss did not improve from 1.35714\n","Epoch 6/150\n","49/49 [==============================] - 45s 914ms/step - loss: 1.0469 - mae: 1.0469 - mse: 1.9791 - val_loss: 1.8893 - val_mae: 1.8893 - val_mse: 6.1907\n","\n","Epoch 00006: val_loss did not improve from 1.35714\n","Epoch 7/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7343 - mae: 0.7343 - mse: 0.9209 - val_loss: 2.6759 - val_mae: 2.6759 - val_mse: 9.7631\n","\n","Epoch 00007: val_loss did not improve from 1.35714\n","Epoch 8/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.8724 - mae: 0.8724 - mse: 1.2973 - val_loss: 2.1164 - val_mae: 2.1164 - val_mse: 7.7882\n","\n","Epoch 00008: val_loss did not improve from 1.35714\n","Epoch 9/150\n","49/49 [==============================] - 45s 915ms/step - loss: 1.0766 - mae: 1.0766 - mse: 1.8262 - val_loss: 1.4212 - val_mae: 1.4212 - val_mse: 3.4543\n","\n","Epoch 00009: val_loss did not improve from 1.35714\n","Epoch 10/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.8640 - mae: 0.8640 - mse: 1.2772 - val_loss: 1.6395 - val_mae: 1.6395 - val_mse: 3.9974\n","\n","Epoch 00010: val_loss did not improve from 1.35714\n","Epoch 11/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.8813 - mae: 0.8813 - mse: 1.3362 - val_loss: 1.5578 - val_mae: 1.5578 - val_mse: 4.2143\n","\n","Epoch 00011: val_loss did not improve from 1.35714\n","Epoch 12/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.8715 - mae: 0.8715 - mse: 1.2872 - val_loss: 5.0138 - val_mae: 5.0138 - val_mse: 29.3144\n","\n","Epoch 00012: val_loss did not improve from 1.35714\n","Epoch 13/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.8647 - mae: 0.8647 - mse: 1.3423 - val_loss: 3.3107 - val_mae: 3.3107 - val_mse: 14.9381\n","\n","Epoch 00013: val_loss did not improve from 1.35714\n","Epoch 14/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7805 - mae: 0.7805 - mse: 1.0610 - val_loss: 3.7585 - val_mae: 3.7585 - val_mse: 17.4284\n","\n","Epoch 00014: val_loss did not improve from 1.35714\n","Epoch 15/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.7984 - mae: 0.7984 - mse: 1.1463 - val_loss: 1.4943 - val_mae: 1.4943 - val_mse: 3.5568\n","\n","Epoch 00015: val_loss did not improve from 1.35714\n","Epoch 16/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.9600 - mae: 0.9600 - mse: 1.6405 - val_loss: 1.8420 - val_mae: 1.8420 - val_mse: 6.1553\n","\n","Epoch 00016: val_loss did not improve from 1.35714\n","Epoch 17/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.9399 - mae: 0.9399 - mse: 1.6151 - val_loss: 1.4484 - val_mae: 1.4484 - val_mse: 3.3562\n","\n","Epoch 00017: val_loss did not improve from 1.35714\n","Epoch 18/150\n","49/49 [==============================] - 45s 915ms/step - loss: 1.0153 - mae: 1.0153 - mse: 1.7653 - val_loss: 2.3370 - val_mae: 2.3370 - val_mse: 8.0985\n","\n","Epoch 00018: val_loss did not improve from 1.35714\n","Epoch 19/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.8995 - mae: 0.8995 - mse: 1.3638 - val_loss: 4.3375 - val_mae: 4.3375 - val_mse: 25.2855\n","\n","Epoch 00019: val_loss did not improve from 1.35714\n","Epoch 20/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.8138 - mae: 0.8138 - mse: 1.1509 - val_loss: 1.5465 - val_mae: 1.5465 - val_mse: 3.5207\n","\n","Epoch 00020: val_loss did not improve from 1.35714\n","Epoch 21/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.7616 - mae: 0.7616 - mse: 1.0865 - val_loss: 1.4615 - val_mae: 1.4615 - val_mse: 3.6339\n","\n","Epoch 00021: val_loss did not improve from 1.35714\n","Epoch 22/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.8288 - mae: 0.8288 - mse: 1.1990 - val_loss: 2.5671 - val_mae: 2.5671 - val_mse: 9.9772\n","\n","Epoch 00022: val_loss did not improve from 1.35714\n","Epoch 23/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7517 - mae: 0.7517 - mse: 0.9633 - val_loss: 4.2225 - val_mae: 4.2225 - val_mse: 21.4257\n","\n","Epoch 00023: val_loss did not improve from 1.35714\n","Epoch 24/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.7458 - mae: 0.7458 - mse: 0.9533 - val_loss: 4.6535 - val_mae: 4.6535 - val_mse: 29.4159\n","\n","Epoch 00024: val_loss did not improve from 1.35714\n","Epoch 25/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.9263 - mae: 0.9263 - mse: 1.5224 - val_loss: 1.8589 - val_mae: 1.8589 - val_mse: 5.3650\n","\n","Epoch 00025: val_loss did not improve from 1.35714\n","Epoch 26/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.8023 - mae: 0.8023 - mse: 1.0923 - val_loss: 1.5282 - val_mae: 1.5282 - val_mse: 3.9614\n","\n","Epoch 00026: val_loss did not improve from 1.35714\n","Epoch 27/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.8407 - mae: 0.8407 - mse: 1.2579 - val_loss: 1.3660 - val_mae: 1.3660 - val_mse: 2.9826\n","\n","Epoch 00027: val_loss did not improve from 1.35714\n","Epoch 28/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.8726 - mae: 0.8726 - mse: 1.2736 - val_loss: 1.2301 - val_mae: 1.2301 - val_mse: 2.5106\n","\n","Epoch 00028: val_loss improved from 1.35714 to 1.23006, saving model to checkpoint-50-epochs-16-batchs.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 29/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.8993 - mae: 0.8993 - mse: 1.3908 - val_loss: 1.3333 - val_mae: 1.3333 - val_mse: 2.8045\n","\n","Epoch 00029: val_loss did not improve from 1.23006\n","Epoch 30/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.9072 - mae: 0.9072 - mse: 1.3945 - val_loss: 1.3100 - val_mae: 1.3100 - val_mse: 3.0391\n","\n","Epoch 00030: val_loss did not improve from 1.23006\n","Epoch 31/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7496 - mae: 0.7496 - mse: 0.9506 - val_loss: 4.2365 - val_mae: 4.2365 - val_mse: 20.9079\n","\n","Epoch 00031: val_loss did not improve from 1.23006\n","Epoch 32/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.9641 - mae: 0.9641 - mse: 1.6170 - val_loss: 1.2926 - val_mae: 1.2926 - val_mse: 2.6312\n","\n","Epoch 00032: val_loss did not improve from 1.23006\n","Epoch 33/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.7047 - mae: 0.7047 - mse: 0.8337 - val_loss: 1.8530 - val_mae: 1.8530 - val_mse: 5.9221\n","\n","Epoch 00033: val_loss did not improve from 1.23006\n","Epoch 34/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.7393 - mae: 0.7393 - mse: 1.0476 - val_loss: 2.2248 - val_mae: 2.2248 - val_mse: 7.2877\n","\n","Epoch 00034: val_loss did not improve from 1.23006\n","Epoch 35/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7220 - mae: 0.7220 - mse: 0.9689 - val_loss: 1.3137 - val_mae: 1.3137 - val_mse: 2.7579\n","\n","Epoch 00035: val_loss did not improve from 1.23006\n","Epoch 36/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.7277 - mae: 0.7277 - mse: 0.9011 - val_loss: 1.9838 - val_mae: 1.9838 - val_mse: 5.7649\n","\n","Epoch 00036: val_loss did not improve from 1.23006\n","Epoch 37/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.7510 - mae: 0.7510 - mse: 1.0043 - val_loss: 1.1466 - val_mae: 1.1466 - val_mse: 2.1452\n","\n","Epoch 00037: val_loss improved from 1.23006 to 1.14659, saving model to checkpoint-50-epochs-16-batchs.h5\n","Epoch 38/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.7645 - mae: 0.7645 - mse: 1.0000 - val_loss: 1.2650 - val_mae: 1.2650 - val_mse: 2.9223\n","\n","Epoch 00038: val_loss did not improve from 1.14659\n","Epoch 39/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.6731 - mae: 0.6731 - mse: 0.7406 - val_loss: 2.5239 - val_mae: 2.5239 - val_mse: 10.3985\n","\n","Epoch 00039: val_loss did not improve from 1.14659\n","Epoch 40/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.8479 - mae: 0.8479 - mse: 1.2252 - val_loss: 2.2543 - val_mae: 2.2543 - val_mse: 7.3544\n","\n","Epoch 00040: val_loss did not improve from 1.14659\n","Epoch 41/150\n","49/49 [==============================] - ETA: 0s - loss: 0.8390 - mae: 0.8390 - mse: 1.2914\n","Epoch 00041: val_loss did not improve from 1.14659\n","Epoch 42/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7091 - mae: 0.7091 - mse: 0.8702 - val_loss: 2.4776 - val_mae: 2.4776 - val_mse: 8.3179\n","\n","Epoch 00042: val_loss did not improve from 1.14659\n","Epoch 43/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6115 - mae: 0.6115 - mse: 0.6591 - val_loss: 1.4151 - val_mae: 1.4151 - val_mse: 3.3833\n","\n","Epoch 00043: val_loss did not improve from 1.14659\n","Epoch 44/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.7456 - mae: 0.7456 - mse: 0.9531 - val_loss: 2.8071 - val_mae: 2.8071 - val_mse: 10.4475\n","\n","Epoch 00044: val_loss did not improve from 1.14659\n","Epoch 45/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.6914 - mae: 0.6914 - mse: 0.8245 - val_loss: 1.4928 - val_mae: 1.4928 - val_mse: 3.5224\n","\n","Epoch 00045: val_loss did not improve from 1.14659\n","Epoch 46/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.7398 - mae: 0.7398 - mse: 0.9396 - val_loss: 4.2335 - val_mae: 4.2335 - val_mse: 22.9940\n","\n","Epoch 00046: val_loss did not improve from 1.14659\n","Epoch 47/150\n","49/49 [==============================] - 47s 953ms/step - loss: 0.6777 - mae: 0.6777 - mse: 0.7913 - val_loss: 1.8608 - val_mae: 1.8608 - val_mse: 6.0268\n","\n","Epoch 00047: val_loss did not improve from 1.14659\n","Epoch 48/150\n","49/49 [==============================] - 45s 917ms/step - loss: 0.7406 - mae: 0.7406 - mse: 0.9278 - val_loss: 2.2903 - val_mae: 2.2903 - val_mse: 7.2323\n","\n","Epoch 00048: val_loss did not improve from 1.14659\n","Epoch 49/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7044 - mae: 0.7044 - mse: 0.8525 - val_loss: 3.4248 - val_mae: 3.4248 - val_mse: 15.1216\n","\n","Epoch 00049: val_loss did not improve from 1.14659\n","Epoch 50/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6219 - mae: 0.6219 - mse: 0.6707 - val_loss: 1.1859 - val_mae: 1.1859 - val_mse: 2.3477\n","\n","Epoch 00050: val_loss did not improve from 1.14659\n","Epoch 51/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6259 - mae: 0.6259 - mse: 0.6858 - val_loss: 1.4816 - val_mae: 1.4816 - val_mse: 3.5819\n","\n","Epoch 00051: val_loss did not improve from 1.14659\n","Epoch 52/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.7007 - mae: 0.7007 - mse: 0.8578 - val_loss: 1.3077 - val_mae: 1.3077 - val_mse: 2.9376\n","\n","Epoch 00052: val_loss did not improve from 1.14659\n","Epoch 53/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.7555 - mae: 0.7555 - mse: 0.9503 - val_loss: 1.3048 - val_mae: 1.3048 - val_mse: 2.6983\n","\n","Epoch 00053: val_loss did not improve from 1.14659\n","Epoch 54/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.7445 - mae: 0.7445 - mse: 0.8739 - val_loss: 3.4678 - val_mae: 3.4678 - val_mse: 14.8110\n","\n","Epoch 00054: val_loss did not improve from 1.14659\n","Epoch 55/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6103 - mae: 0.6103 - mse: 0.6880 - val_loss: 3.0736 - val_mae: 3.0736 - val_mse: 12.4278\n","\n","Epoch 00055: val_loss did not improve from 1.14659\n","Epoch 56/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6192 - mae: 0.6192 - mse: 0.6518 - val_loss: 1.6789 - val_mae: 1.6789 - val_mse: 4.9150\n","\n","Epoch 00056: val_loss did not improve from 1.14659\n","Epoch 57/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6103 - mae: 0.6103 - mse: 0.6919 - val_loss: 1.7826 - val_mae: 1.7826 - val_mse: 4.8732\n","\n","Epoch 00057: val_loss did not improve from 1.14659\n","Epoch 58/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6179 - mae: 0.6179 - mse: 0.6385 - val_loss: 1.2055 - val_mae: 1.2055 - val_mse: 2.3905\n","\n","Epoch 00058: val_loss did not improve from 1.14659\n","Epoch 59/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6584 - mae: 0.6584 - mse: 0.7480 - val_loss: 4.3685 - val_mae: 4.3685 - val_mse: 22.2506\n","\n","Epoch 00059: val_loss did not improve from 1.14659\n","Epoch 60/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6879 - mae: 0.6879 - mse: 0.8258 - val_loss: 3.8856 - val_mae: 3.8856 - val_mse: 19.0277\n","\n","Epoch 00060: val_loss did not improve from 1.14659\n","Epoch 61/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6472 - mae: 0.6472 - mse: 0.7377 - val_loss: 4.5334 - val_mae: 4.5334 - val_mse: 26.8227\n","\n","Epoch 00061: val_loss did not improve from 1.14659\n","Epoch 62/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.7635 - mae: 0.7635 - mse: 1.0643 - val_loss: 3.0949 - val_mae: 3.0949 - val_mse: 11.8300\n","\n","Epoch 00062: val_loss did not improve from 1.14659\n","Epoch 63/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6522 - mae: 0.6522 - mse: 0.7232 - val_loss: 2.1642 - val_mae: 2.1642 - val_mse: 7.0962\n","\n","Epoch 00063: val_loss did not improve from 1.14659\n","Epoch 64/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.6423 - mae: 0.6423 - mse: 0.6746 - val_loss: 1.5381 - val_mae: 1.5381 - val_mse: 3.8159\n","\n","Epoch 00064: val_loss did not improve from 1.14659\n","Epoch 65/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5941 - mae: 0.5941 - mse: 0.6015 - val_loss: 1.4301 - val_mae: 1.4301 - val_mse: 3.1814\n","\n","Epoch 00065: val_loss did not improve from 1.14659\n","Epoch 66/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5878 - mae: 0.5878 - mse: 0.5686 - val_loss: 2.1203 - val_mae: 2.1203 - val_mse: 6.5910\n","\n","Epoch 00066: val_loss did not improve from 1.14659\n","Epoch 67/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.6128 - mae: 0.6128 - mse: 0.6700 - val_loss: 2.8199 - val_mae: 2.8199 - val_mse: 11.6335\n","\n","Epoch 00067: val_loss did not improve from 1.14659\n","Epoch 68/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6206 - mae: 0.6206 - mse: 0.6702 - val_loss: 1.5653 - val_mae: 1.5653 - val_mse: 3.8384\n","\n","Epoch 00068: val_loss did not improve from 1.14659\n","Epoch 69/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5428 - mae: 0.5428 - mse: 0.4906 - val_loss: 1.2875 - val_mae: 1.2875 - val_mse: 2.6764\n","\n","Epoch 00069: val_loss did not improve from 1.14659\n","Epoch 70/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5612 - mae: 0.5612 - mse: 0.5544 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 2.1910\n","\n","Epoch 00070: val_loss did not improve from 1.14659\n","Epoch 71/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5202 - mae: 0.5202 - mse: 0.4420 - val_loss: 1.4683 - val_mae: 1.4683 - val_mse: 3.5258\n","\n","Epoch 00071: val_loss did not improve from 1.14659\n","Epoch 72/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5920 - mae: 0.5920 - mse: 0.5808 - val_loss: 2.2213 - val_mae: 2.2213 - val_mse: 7.5576\n","\n","Epoch 00072: val_loss did not improve from 1.14659\n","Epoch 73/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.5278 - mae: 0.5278 - mse: 0.4852 - val_loss: 1.1856 - val_mae: 1.1856 - val_mse: 2.3606\n","\n","Epoch 00073: val_loss did not improve from 1.14659\n","Epoch 74/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4815 - mae: 0.4815 - mse: 0.4035 - val_loss: 2.8159 - val_mae: 2.8159 - val_mse: 10.2879\n","\n","Epoch 00074: val_loss did not improve from 1.14659\n","Epoch 75/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5794 - mae: 0.5794 - mse: 0.5610 - val_loss: 3.2345 - val_mae: 3.2345 - val_mse: 14.1156\n","\n","Epoch 00075: val_loss did not improve from 1.14659\n","Epoch 76/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5910 - mae: 0.5910 - mse: 0.6023 - val_loss: 1.6548 - val_mae: 1.6548 - val_mse: 4.5342\n","\n","Epoch 00076: val_loss did not improve from 1.14659\n","Epoch 77/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5024 - mae: 0.5024 - mse: 0.4436 - val_loss: 2.2882 - val_mae: 2.2882 - val_mse: 6.9084\n","\n","Epoch 00077: val_loss did not improve from 1.14659\n","Epoch 78/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5847 - mae: 0.5847 - mse: 0.5823 - val_loss: 1.4079 - val_mae: 1.4079 - val_mse: 2.9354\n","\n","Epoch 00078: val_loss did not improve from 1.14659\n","Epoch 79/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5455 - mae: 0.5455 - mse: 0.5073 - val_loss: 1.0634 - val_mae: 1.0634 - val_mse: 1.9124\n","\n","Epoch 00079: val_loss improved from 1.14659 to 1.06337, saving model to checkpoint-50-epochs-16-batchs.h5\n","Epoch 80/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.5429 - mae: 0.5429 - mse: 0.4883 - val_loss: 1.7219 - val_mae: 1.7219 - val_mse: 4.4327\n","\n","Epoch 00080: val_loss did not improve from 1.06337\n","Epoch 81/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5641 - mae: 0.5641 - mse: 0.5239 - val_loss: 2.2586 - val_mae: 2.2586 - val_mse: 7.5002\n","\n","Epoch 00081: val_loss did not improve from 1.06337\n","Epoch 82/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.5181 - mae: 0.5181 - mse: 0.4670 - val_loss: 1.6903 - val_mae: 1.6903 - val_mse: 4.2796\n","\n","Epoch 00082: val_loss did not improve from 1.06337\n","Epoch 83/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5028 - mae: 0.5028 - mse: 0.4641 - val_loss: 2.6901 - val_mae: 2.6901 - val_mse: 10.3983\n","\n","Epoch 00083: val_loss did not improve from 1.06337\n","Epoch 84/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4705 - mae: 0.4705 - mse: 0.3711 - val_loss: 1.2089 - val_mae: 1.2089 - val_mse: 2.3695\n","\n","Epoch 00084: val_loss did not improve from 1.06337\n","Epoch 85/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5244 - mae: 0.5244 - mse: 0.4942 - val_loss: 1.2835 - val_mae: 1.2835 - val_mse: 2.8972\n","\n","Epoch 00085: val_loss did not improve from 1.06337\n","Epoch 86/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.5026 - mae: 0.5026 - mse: 0.4527 - val_loss: 1.1948 - val_mae: 1.1948 - val_mse: 2.2688\n","\n","Epoch 00086: val_loss did not improve from 1.06337\n","Epoch 87/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5032 - mae: 0.5032 - mse: 0.4154 - val_loss: 1.4688 - val_mae: 1.4688 - val_mse: 3.5710\n","\n","Epoch 00087: val_loss did not improve from 1.06337\n","Epoch 88/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5024 - mae: 0.5024 - mse: 0.4269 - val_loss: 1.1769 - val_mae: 1.1769 - val_mse: 2.2887\n","\n","Epoch 00088: val_loss did not improve from 1.06337\n","Epoch 89/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5244 - mae: 0.5244 - mse: 0.4532 - val_loss: 1.2413 - val_mae: 1.2413 - val_mse: 2.3100\n","\n","Epoch 00089: val_loss did not improve from 1.06337\n","Epoch 90/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.6350 - mae: 0.6350 - mse: 0.6488 - val_loss: 1.6776 - val_mae: 1.6776 - val_mse: 4.2674\n","\n","Epoch 00090: val_loss did not improve from 1.06337\n","Epoch 91/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4475 - mae: 0.4475 - mse: 0.3264 - val_loss: 1.3960 - val_mae: 1.3960 - val_mse: 3.0968\n","\n","Epoch 00091: val_loss did not improve from 1.06337\n","Epoch 92/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5041 - mae: 0.5041 - mse: 0.4233 - val_loss: 1.4490 - val_mae: 1.4490 - val_mse: 3.4028\n","\n","Epoch 00092: val_loss did not improve from 1.06337\n","Epoch 93/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.5014 - mae: 0.5014 - mse: 0.4339 - val_loss: 2.0638 - val_mae: 2.0638 - val_mse: 6.9322\n","\n","Epoch 00093: val_loss did not improve from 1.06337\n","Epoch 94/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4401 - mae: 0.4401 - mse: 0.3407 - val_loss: 2.1447 - val_mae: 2.1447 - val_mse: 6.1564\n","\n","Epoch 00094: val_loss did not improve from 1.06337\n","Epoch 95/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5488 - mae: 0.5488 - mse: 0.5099 - val_loss: 1.2021 - val_mae: 1.2021 - val_mse: 2.4237\n","\n","Epoch 00095: val_loss did not improve from 1.06337\n","Epoch 96/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4684 - mae: 0.4684 - mse: 0.3726 - val_loss: 1.0474 - val_mae: 1.0474 - val_mse: 1.9742\n","\n","Epoch 00096: val_loss improved from 1.06337 to 1.04736, saving model to checkpoint-50-epochs-16-batchs.h5\n","Epoch 97/150\n","49/49 [==============================] - 47s 955ms/step - loss: 0.4507 - mae: 0.4507 - mse: 0.3332 - val_loss: 1.3354 - val_mae: 1.3354 - val_mse: 2.7439\n","\n","Epoch 00097: val_loss did not improve from 1.04736\n","Epoch 98/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4855 - mae: 0.4855 - mse: 0.4035 - val_loss: 2.4562 - val_mae: 2.4562 - val_mse: 8.5659\n","\n","Epoch 00098: val_loss did not improve from 1.04736\n","Epoch 99/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4430 - mae: 0.4430 - mse: 0.3135 - val_loss: 1.3303 - val_mae: 1.3303 - val_mse: 3.2094\n","\n","Epoch 00099: val_loss did not improve from 1.04736\n","Epoch 100/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.5236 - mae: 0.5236 - mse: 0.4536 - val_loss: 1.4657 - val_mae: 1.4657 - val_mse: 3.3427\n","\n","Epoch 00100: val_loss did not improve from 1.04736\n","Epoch 101/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4292 - mae: 0.4292 - mse: 0.2993 - val_loss: 1.3935 - val_mae: 1.3935 - val_mse: 3.2653\n","\n","Epoch 00101: val_loss did not improve from 1.04736\n","Epoch 102/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4451 - mae: 0.4451 - mse: 0.3241 - val_loss: 1.0876 - val_mae: 1.0876 - val_mse: 1.9134\n","\n","Epoch 00102: val_loss did not improve from 1.04736\n","Epoch 103/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4279 - mae: 0.4279 - mse: 0.2938 - val_loss: 3.6953 - val_mae: 3.6953 - val_mse: 16.2500\n","\n","Epoch 00103: val_loss did not improve from 1.04736\n","Epoch 104/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5082 - mae: 0.5082 - mse: 0.4211 - val_loss: 1.4149 - val_mae: 1.4149 - val_mse: 3.3542\n","\n","Epoch 00104: val_loss did not improve from 1.04736\n","Epoch 105/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4702 - mae: 0.4702 - mse: 0.3615 - val_loss: 1.2459 - val_mae: 1.2459 - val_mse: 2.5019\n","\n","Epoch 00105: val_loss did not improve from 1.04736\n","Epoch 106/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4772 - mae: 0.4772 - mse: 0.3738 - val_loss: 2.5286 - val_mae: 2.5286 - val_mse: 8.9965\n","\n","Epoch 00106: val_loss did not improve from 1.04736\n","Epoch 107/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5369 - mae: 0.5369 - mse: 0.5015 - val_loss: 4.9856 - val_mae: 4.9856 - val_mse: 30.6959\n","\n","Epoch 00107: val_loss did not improve from 1.04736\n","Epoch 108/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5226 - mae: 0.5226 - mse: 0.4624 - val_loss: 1.1066 - val_mae: 1.1066 - val_mse: 1.9841\n","\n","Epoch 00108: val_loss did not improve from 1.04736\n","Epoch 109/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5185 - mae: 0.5185 - mse: 0.4633 - val_loss: 1.8830 - val_mae: 1.8830 - val_mse: 5.5483\n","\n","Epoch 00109: val_loss did not improve from 1.04736\n","Epoch 110/150\n","49/49 [==============================] - 47s 953ms/step - loss: 0.4706 - mae: 0.4706 - mse: 0.3768 - val_loss: 1.2147 - val_mae: 1.2147 - val_mse: 2.3439\n","\n","Epoch 00110: val_loss did not improve from 1.04736\n","Epoch 111/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4666 - mae: 0.4666 - mse: 0.3636 - val_loss: 1.1376 - val_mae: 1.1376 - val_mse: 1.9932\n","\n","Epoch 00111: val_loss did not improve from 1.04736\n","Epoch 112/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.5050 - mae: 0.5050 - mse: 0.4360 - val_loss: 1.9614 - val_mae: 1.9614 - val_mse: 5.8123\n","\n","Epoch 00112: val_loss did not improve from 1.04736\n","Epoch 113/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4856 - mae: 0.4856 - mse: 0.3857 - val_loss: 1.4967 - val_mae: 1.4967 - val_mse: 3.5284\n","\n","Epoch 00113: val_loss did not improve from 1.04736\n","Epoch 114/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4515 - mae: 0.4515 - mse: 0.3422 - val_loss: 1.3802 - val_mae: 1.3802 - val_mse: 2.9152\n","\n","Epoch 00114: val_loss did not improve from 1.04736\n","Epoch 115/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4512 - mae: 0.4512 - mse: 0.3315 - val_loss: 1.4372 - val_mae: 1.4372 - val_mse: 3.5224\n","\n","Epoch 00115: val_loss did not improve from 1.04736\n","Epoch 116/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4181 - mae: 0.4181 - mse: 0.2745 - val_loss: 1.1933 - val_mae: 1.1933 - val_mse: 2.3892\n","\n","Epoch 00116: val_loss did not improve from 1.04736\n","Epoch 117/150\n","49/49 [==============================] - 47s 953ms/step - loss: 0.3984 - mae: 0.3984 - mse: 0.2738 - val_loss: 1.3934 - val_mae: 1.3934 - val_mse: 3.1247\n","\n","Epoch 00117: val_loss did not improve from 1.04736\n","Epoch 118/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4055 - mae: 0.4055 - mse: 0.2654 - val_loss: 1.2556 - val_mae: 1.2556 - val_mse: 2.5128\n","\n","Epoch 00118: val_loss did not improve from 1.04736\n","Epoch 119/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.3910 - mae: 0.3910 - mse: 0.2526 - val_loss: 1.0691 - val_mae: 1.0691 - val_mse: 1.8045\n","\n","Epoch 00119: val_loss did not improve from 1.04736\n","Epoch 120/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.3700 - mae: 0.3700 - mse: 0.2143 - val_loss: 1.0862 - val_mae: 1.0862 - val_mse: 2.0116\n","\n","Epoch 00120: val_loss did not improve from 1.04736\n","Epoch 121/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4204 - mae: 0.4204 - mse: 0.2986 - val_loss: 2.8133 - val_mae: 2.8133 - val_mse: 11.4592\n","\n","Epoch 00121: val_loss did not improve from 1.04736\n","Epoch 122/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4273 - mae: 0.4273 - mse: 0.3352 - val_loss: 1.2363 - val_mae: 1.2363 - val_mse: 2.3767\n","\n","Epoch 00122: val_loss did not improve from 1.04736\n","Epoch 123/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3879 - mae: 0.3879 - mse: 0.2457 - val_loss: 1.4668 - val_mae: 1.4668 - val_mse: 3.1985\n","\n","Epoch 00123: val_loss did not improve from 1.04736\n","Epoch 124/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.3719 - mae: 0.3719 - mse: 0.2205 - val_loss: 1.2066 - val_mae: 1.2066 - val_mse: 2.3179\n","\n","Epoch 00124: val_loss did not improve from 1.04736\n","Epoch 125/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4253 - mae: 0.4253 - mse: 0.2973 - val_loss: 1.1893 - val_mae: 1.1893 - val_mse: 2.2753\n","\n","Epoch 00125: val_loss did not improve from 1.04736\n","Epoch 126/150\n","49/49 [==============================] - 47s 953ms/step - loss: 0.4071 - mae: 0.4071 - mse: 0.2846 - val_loss: 1.0308 - val_mae: 1.0308 - val_mse: 1.7756\n","\n","Epoch 00126: val_loss improved from 1.04736 to 1.03079, saving model to checkpoint-50-epochs-16-batchs.h5\n","Epoch 127/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3658 - mae: 0.3658 - mse: 0.2327 - val_loss: 1.0575 - val_mae: 1.0575 - val_mse: 1.7973\n","\n","Epoch 00127: val_loss did not improve from 1.03079\n","Epoch 128/150\n","49/49 [==============================] - 47s 953ms/step - loss: 0.4260 - mae: 0.4260 - mse: 0.2980 - val_loss: 1.0835 - val_mae: 1.0835 - val_mse: 1.9324\n","\n","Epoch 00128: val_loss did not improve from 1.03079\n","Epoch 129/150\n","49/49 [==============================] - 45s 917ms/step - loss: 0.3687 - mae: 0.3687 - mse: 0.2261 - val_loss: 1.1883 - val_mae: 1.1883 - val_mse: 2.2841\n","\n","Epoch 00129: val_loss did not improve from 1.03079\n","Epoch 130/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3578 - mae: 0.3578 - mse: 0.2189 - val_loss: 1.0752 - val_mae: 1.0752 - val_mse: 1.8804\n","\n","Epoch 00130: val_loss did not improve from 1.03079\n","Epoch 131/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.3745 - mae: 0.3745 - mse: 0.2330 - val_loss: 2.0043 - val_mae: 2.0043 - val_mse: 5.8290\n","\n","Epoch 00131: val_loss did not improve from 1.03079\n","Epoch 132/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4267 - mae: 0.4267 - mse: 0.3106 - val_loss: 1.3681 - val_mae: 1.3681 - val_mse: 2.6707\n","\n","Epoch 00132: val_loss did not improve from 1.03079\n","Epoch 133/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.4433 - mae: 0.4433 - mse: 0.4518 - val_loss: 1.2242 - val_mae: 1.2242 - val_mse: 2.5508\n","\n","Epoch 00133: val_loss did not improve from 1.03079\n","Epoch 134/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.5141 - mae: 0.5141 - mse: 0.4807 - val_loss: 1.5548 - val_mae: 1.5548 - val_mse: 3.5736\n","\n","Epoch 00134: val_loss did not improve from 1.03079\n","Epoch 135/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4560 - mae: 0.4560 - mse: 0.4049 - val_loss: 1.1433 - val_mae: 1.1433 - val_mse: 2.2355\n","\n","Epoch 00135: val_loss did not improve from 1.03079\n","Epoch 136/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4807 - mae: 0.4807 - mse: 0.3824 - val_loss: 1.2952 - val_mae: 1.2952 - val_mse: 2.6063\n","\n","Epoch 00136: val_loss did not improve from 1.03079\n","Epoch 137/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.3927 - mae: 0.3927 - mse: 0.2463 - val_loss: 1.2241 - val_mae: 1.2241 - val_mse: 2.3781\n","\n","Epoch 00137: val_loss did not improve from 1.03079\n","Epoch 138/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4620 - mae: 0.4620 - mse: 0.3526 - val_loss: 1.2292 - val_mae: 1.2292 - val_mse: 2.2710\n","\n","Epoch 00138: val_loss did not improve from 1.03079\n","Epoch 139/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3491 - mae: 0.3491 - mse: 0.1973 - val_loss: 1.7827 - val_mae: 1.7827 - val_mse: 4.5483\n","\n","Epoch 00139: val_loss did not improve from 1.03079\n","Epoch 140/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.3587 - mae: 0.3587 - mse: 0.2082 - val_loss: 2.0776 - val_mae: 2.0776 - val_mse: 5.8611\n","\n","Epoch 00140: val_loss did not improve from 1.03079\n","Epoch 141/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3795 - mae: 0.3795 - mse: 0.2560 - val_loss: 1.1981 - val_mae: 1.1981 - val_mse: 2.2891\n","\n","Epoch 00141: val_loss did not improve from 1.03079\n","Epoch 142/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.3746 - mae: 0.3746 - mse: 0.2362 - val_loss: 1.8129 - val_mae: 1.8129 - val_mse: 4.7443\n","\n","Epoch 00142: val_loss did not improve from 1.03079\n","Epoch 143/150\n","49/49 [==============================] - 45s 916ms/step - loss: 0.4000 - mae: 0.4000 - mse: 0.2680 - val_loss: 1.9016 - val_mae: 1.9016 - val_mse: 5.0865\n","\n","Epoch 00143: val_loss did not improve from 1.03079\n","Epoch 144/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.4064 - mae: 0.4064 - mse: 0.2639 - val_loss: 1.1618 - val_mae: 1.1618 - val_mse: 2.2813\n","\n","Epoch 00144: val_loss did not improve from 1.03079\n","Epoch 145/150\n","49/49 [==============================] - 47s 955ms/step - loss: 0.4179 - mae: 0.4179 - mse: 0.2762 - val_loss: 1.6525 - val_mae: 1.6525 - val_mse: 3.9637\n","\n","Epoch 00145: val_loss did not improve from 1.03079\n","Epoch 146/150\n","49/49 [==============================] - 45s 915ms/step - loss: 0.4072 - mae: 0.4072 - mse: 0.2854 - val_loss: 1.0566 - val_mae: 1.0566 - val_mse: 1.7642\n","\n","Epoch 00146: val_loss did not improve from 1.03079\n","Epoch 147/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4004 - mae: 0.4004 - mse: 0.2574 - val_loss: 1.1493 - val_mae: 1.1493 - val_mse: 2.0766\n","\n","Epoch 00147: val_loss did not improve from 1.03079\n","Epoch 148/150\n","49/49 [==============================] - 45s 912ms/step - loss: 0.3728 - mae: 0.3728 - mse: 0.2291 - val_loss: 1.5486 - val_mae: 1.5486 - val_mse: 3.5716\n","\n","Epoch 00148: val_loss did not improve from 1.03079\n","Epoch 149/150\n","49/49 [==============================] - 45s 913ms/step - loss: 0.3546 - mae: 0.3546 - mse: 0.2025 - val_loss: 1.3090 - val_mae: 1.3090 - val_mse: 2.6350\n","\n","Epoch 00149: val_loss did not improve from 1.03079\n","Epoch 150/150\n","49/49 [==============================] - 45s 914ms/step - loss: 0.4621 - mae: 0.4621 - mse: 0.3615 - val_loss: 1.1343 - val_mae: 1.1343 - val_mse: 2.0547\n","\n","Epoch 00150: val_loss did not improve from 1.03079\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68RjrIIQz31S","executionInfo":{"status":"ok","timestamp":1629100775517,"user_tz":-540,"elapsed":272,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"1b7a683c-da79-4d93-83ae-8b6d5eaf9295"},"source":["model.predict(bones[200,2].reshape(1,256,256,1))"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[12.6]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy6c4ZqJ9lAx","executionInfo":{"status":"ok","timestamp":1629100658109,"user_tz":-540,"elapsed":256,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"33463400-14f4-4c25-969a-6887bb99723c"},"source":["train_y[200]"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11.463013698630137"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQ2d6WlW9roR","executionInfo":{"status":"ok","timestamp":1629100749743,"user_tz":-540,"elapsed":291,"user":{"displayName":"이승규","photoUrl":"","userId":"02897177244865781862"}},"outputId":"6b48c8cf-f2e0-4e52-8299-34ba5da858f7"},"source":[""],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"J5K0LgHp-BiK"},"source":[""],"execution_count":null,"outputs":[]}]}